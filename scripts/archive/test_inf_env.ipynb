{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from typet5.data import GitRepo\n",
    "from typet5.type_env import (\n",
    "    AnnotPath,\n",
    "    MypyChecker,\n",
    "    SelectAnnotations,\n",
    "    TypeInfAction,\n",
    "    TypeInfEnv,\n",
    "    TypeInfState,\n",
    "    collect_annotations,\n",
    "    mypy_checker,\n",
    ")\n",
    "from typet5.utils import cst, proj_root, read_file, seq_flatten, tqdm, write_file\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "datadir = Path(os.getenv(\"datadir\"))\n",
    "repos_dir = datadir / \"SPOT-data/repos\"\n",
    "\n",
    "useful_repos_path = proj_root() / \"scripts\" / \"useful_repos.pkl\"\n",
    "with useful_repos_path.open(\"rb\") as f:\n",
    "    useful_repos: list[GitRepo] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typet5.visualization import display_code_sequence\n",
    "\n",
    "\n",
    "def test_policy(env: TypeInfEnv, pi: Callable[[TypeInfState], TypeInfAction]):\n",
    "    env.reset()\n",
    "    state_seq = [str(env.state)]\n",
    "    n_steps = len(env.state.to_annot)\n",
    "    for i in tqdm(range(n_steps)):\n",
    "        if env.step(act := pi(env.state)):\n",
    "            type_str = env.state.module.code_for_node(act.type)\n",
    "            print(f\"Action rejected: [{str(act.path)}: {type_str}]\")\n",
    "        state_seq.append(str(env.state))\n",
    "\n",
    "    return display_code_sequence(state_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daemon stopped\n"
     ]
    }
   ],
   "source": [
    "# remove `inference_dir` if it exists\n",
    "if \"inf_checker\" in globals():\n",
    "    inf_checker.close()\n",
    "\n",
    "inference_dir = Path(\"data/code_output/inference\")\n",
    "if inference_dir.exists():\n",
    "    shutil.rmtree(inference_dir)\n",
    "inference_dir.mkdir(parents=True)\n",
    "write_file(inference_dir / \"env_code_1.py\", read_file(\"data/code/env_code_1.py\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Daemon is still alive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5faaa974b9554d418829ac47a75207a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action rejected: ['fib.n': str]\n",
      "Action rejected: ['fib.<return>': str]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee2036099a846c293f1b389b8fffb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value=\"<pre style='line-height:1.2;'>\\nnum_errors: 0\\nnum_to_annot: 11\\nto_annotate: [Annot…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "from typet5.type_env import type_inf_env\n",
    "\n",
    "inf_checker = MypyChecker(\".venv/bin/dmypy\", inference_dir)\n",
    "\n",
    "with type_inf_env(\n",
    "    inf_checker,\n",
    "    inference_dir / \"env_code_1.py\",\n",
    "    SelectAnnotations.select_all_paths,\n",
    "    print_mypy_output=False,\n",
    ") as env:\n",
    "    display(test_policy(env, lambda s: TypeInfAction(s.to_annot[0], cst.Name(\"str\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_dir = datadir / \"checkpoints/saved/SPOT-CodeT5-with_margin/\"\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "from transformers.models.t5 import T5ForConditionalGeneration\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer: RobertaTokenizer = RobertaTokenizer.from_pretrained(model_dir)\n",
    "model: T5ForConditionalGeneration = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_dir\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers.models.t5 import T5ForConditionalGeneration\n",
    "\n",
    "from typet5.type_env import apply_annotations\n",
    "from typet5.utils import join_str\n",
    "\n",
    "\n",
    "def greedy_policy_from_model(\n",
    "    model: T5ForConditionalGeneration, tokenizer: RobertaTokenizer\n",
    "):\n",
    "    def pi(s: TypeInfState) -> TypeInfAction:\n",
    "        path = s.to_annot[0]\n",
    "        annot = cst.Annotation(cst.Name(\"SPOT_TYPE_MASK\"))\n",
    "        m1 = apply_annotations(s.module, {path: annot})\n",
    "        code_input = m1.code.replace(\"SPOT_TYPE_MASK\", \"<extra_id_0>\")\n",
    "        dec = model.generate(\n",
    "            tokenizer.encode(code_input, return_tensors=\"pt\").to(model.device),\n",
    "            max_length=20,\n",
    "            num_beams=16,\n",
    "        )[0]\n",
    "        pred = tokenizer.decode(dec, skip_special_tokens=True)\n",
    "        print(f\"Prediction for {path.__str__()}:\", pred)\n",
    "        try:\n",
    "            type_ex = cst.parse_expression(pred)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to parse:\", pred)\n",
    "            type_ex = cst.Name(\"Any\")\n",
    "        return TypeInfAction(path, type_ex)\n",
    "\n",
    "    return pi\n",
    "\n",
    "\n",
    "def planner_policy_from_model(\n",
    "    model: T5ForConditionalGeneration, tokenizer: RobertaTokenizer\n",
    "):\n",
    "    def pi(s: TypeInfState) -> TypeInfAction:\n",
    "        path = s.to_annot[0]\n",
    "        annot = cst.Annotation(cst.Name(\"SPOT_TYPE_MASK\"))\n",
    "        m1 = apply_annotations(s.module, {p: annot for p in s.to_annot})\n",
    "        code_segs = m1.code.split(\"SPOT_TYPE_MASK\")\n",
    "        mask_tokens = [f\"<extra_id_{i}>\" for i in range(len(s.to_annot))]\n",
    "        code_input = join_str(code_segs, mask_tokens)\n",
    "        dec = model.generate(\n",
    "            tokenizer.encode(code_input, return_tensors=\"pt\").to(model.device),\n",
    "            max_length=56,\n",
    "            num_beams=16,\n",
    "        )[0]\n",
    "        dec = tokenizer.decode(dec)\n",
    "        mr = re.match(r\".+<extra_id_0>(.+)<extra_id_1>.+\", dec)\n",
    "        if mr is None:\n",
    "            mr = re.match(r\".+<extra_id_0>(.+)</s>\", dec)\n",
    "        if mr is not None:\n",
    "            type_str = mr.group(1)\n",
    "            print(f\"Prediction for {path.__str__()}:\", type_str)\n",
    "            try:\n",
    "                type_ex = cst.parse_expression(type_str)\n",
    "            except Exception as e:\n",
    "                print(\"Failed to parse as type:\", type_str)\n",
    "                type_ex = cst.Name(\"Any\")\n",
    "        else:\n",
    "            print(f\"Failed to parse model output: {dec}\")\n",
    "            type_ex = cst.Name(\"Any\")\n",
    "        return TypeInfAction(path, type_ex)\n",
    "\n",
    "    return pi\n",
    "\n",
    "\n",
    "greedy_policy = greedy_policy_from_model(model, tokenizer)\n",
    "planner_policy = planner_policy_from_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc928fd9a884c9599e6337f5fb62e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for 'fib.n': int\n",
      "Prediction for 'fib.<return>': int\n",
      "Prediction for 'foo.bar': int\n",
      "Prediction for 'foo.<return>': int\n",
      "Prediction for 'int_add.a': int\n",
      "Prediction for 'int_add.b': int\n",
      "Action rejected: ['int_add.b': int]\n",
      "Prediction for 'int_add.<return>': str\n",
      "Prediction for 'int_tripple_add.a': int\n",
      "Prediction for 'int_tripple_add.b': Annotated[Any, int]\n",
      "Prediction for 'int_tripple_add.c': int\n",
      "Prediction for 'int_tripple_add.<return>': int\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8b7a56009e4586b8c64aeadf20d004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value=\"<pre style='line-height:1.2;'>\\nnum_errors: 0\\nnum_to_annot: 11\\nto_annotate: [Annot…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with type_inf_env(\n",
    "    inf_checker,\n",
    "    inference_dir / \"env_code_1.py\",\n",
    "    SelectAnnotations.select_all_paths,\n",
    "    print_mypy_output=False,\n",
    ") as env:\n",
    "    display(test_policy(env, greedy_policy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb07aa22d19e4a2196a6e696ce337713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for 'fib.n': int\n",
      "Prediction for 'fib.<return>': int\n",
      "Prediction for 'foo.bar': int\n",
      "Prediction for 'foo.<return>': int\n",
      "Prediction for 'int_add.a': int\n",
      "Prediction for 'int_add.b': int, c : int\n",
      "Failed to parse as type: int, c : int\n",
      "Prediction for 'int_add.<return>': str\n",
      "Prediction for 'int_tripple_add.a': int\n",
      "Prediction for 'int_tripple_add.b': Any\n",
      "Prediction for 'int_tripple_add.c': Any\n",
      "Prediction for 'int_tripple_add.<return>': str\n"
     ]
    }
   ],
   "source": [
    "with type_inf_env(\n",
    "    inf_checker,\n",
    "    inference_dir / \"env_code_1.py\",\n",
    "    SelectAnnotations.select_all_paths,\n",
    "    print_mypy_output=False,\n",
    ") as env:\n",
    "    display(test_policy(env, planner_policy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_src = proj_root() / \"src/spot/utils.py\"\n",
    "write_file(\n",
    "    inference_dir / test_src.name,\n",
    "    read_file(test_src).replace(\"[added by SPOT]\", \"[MASK]\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Daemon is still alive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329a308fa4e24f25be6d82e9fb2bd1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for 'read_file.<return>': str\n",
      "Prediction for 'write_file.content': str\n",
      "Prediction for 'write_file.<return>': None\n",
      "Prediction for 'proj_root.<return>': Path\n",
      "Prediction for 'seq_flatten.xs': Sequence[Any]\n",
      "Prediction for 'seq_flatten.<return>': Sequence[Any]\n",
      "Action rejected: ['seq_flatten.<return>': Sequence[Any]]\n",
      "Prediction for 'join_str.segs': Sequence[Any]\n",
      "Prediction for 'join_str.seps': Sequence[Any]\n",
      "Prediction for 'join_str.<return>': str\n",
      "Prediction for 'accuracy_by_labels.y_preds': Sequence[Any]\n",
      "Prediction for 'accuracy_by_labels.y_true': Sequence[Any]\n",
      "Prediction for 'accuracy_by_labels.top_k': Optional[int]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8803291a8124ddbb3203caf0bef9b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value=\"<pre style='line-height:1.2;'>\\nnum_errors: 1\\nnum_to_annot: 12\\nto_annotate: [Annot…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf_checker = MypyChecker(\".venv/bin/dmypy\", inference_dir)\n",
    "with type_inf_env(\n",
    "    inf_checker,\n",
    "    inference_dir / test_src.name,\n",
    "    SelectAnnotations.select_annotated,\n",
    "    print_mypy_output=False,\n",
    ") as env:\n",
    "    display(test_policy(env, greedy_policy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daemon started\n",
      "Daemon started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [16:34<?, ?it/s]\n",
      " 20%|██        | 3/15 [09:53<39:32, 197.72s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daemon stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [16:58<?, ?it/s]\n",
      " 20%|██        | 3/15 [10:17<41:11, 205.98s/it]\n",
      "\n",
      "\n",
      "100%|██████████| 2/2 [00:52<00:00, 26.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daemon stopped\n",
      "479 checks in 69.5186333656311 seconds\n",
      "6.890239016649167 checks/second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typet5.type_env import test_inference_performance\n",
    "from typet5.utils import parallel_map_unordered\n",
    "\n",
    "test_dirs = [r.repo_dir(repos_dir) for r in useful_repos[:2] if r.lines_of_code < 10000]\n",
    "with ProcessPoolExecutor(max_workers=10) as executor:\n",
    "    results = parallel_map_unordered(test_inference_performance, test_dirs, executor)\n",
    "n_checks = sum(r[\"n_checks\"] for r in results)\n",
    "total_time = sum(r[\"time\"] for r in results)\n",
    "print(f\"{n_checks} checks in {total_time} seconds\")\n",
    "print(f\"{n_checks / total_time} checks/second\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_dict = {\"c\": 1, \"b\": 2, \"0\": 5}\n",
    "next(ex_dict.__iter__())\n",
    "next(ex_dict.__iter__())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
